{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beebe9cf-d949-440c-8c8a-de91498d55ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import inspect\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import traceback\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from feeders.feeder_ntu import Feeder\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ZINC\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GINEConv, global_add_pool\n",
    "import inspect\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import Dropout, Linear, Sequential\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.nn.resolver import (\n",
    "    activation_resolver,\n",
    "    normalization_resolver,\n",
    ")\n",
    "from torch_geometric.typing import Adj\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "\n",
    "from mamba_ssm import Mamba\n",
    "from torch_geometric.utils import degree, sort_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630af9b4-9dc7-4ad2-9ca8-d1e57dd285c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_seed(seed):\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # torch.backends.cudnn.enabled = True\n",
    "    # training speed is too slow if set to True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # on cuda 11 cudnn8, the default algorithm is very slow\n",
    "    # unlike on cuda 10, the default works well\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78031e0e-f212-41a2-8fe9-d2eb91a637b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(self, phase='train'):\n",
    "    if phase=='train':\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            dataset=Feeder('data/ntu/NTU60_CS.npz', split='train', p_interval =[0.5, 1], window_size=32),\n",
    "            batch_size=16,\n",
    "            num_workers=0,\n",
    "            worker_init_fn=init_seed)\n",
    "    else:\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            dataset=Feeder('data/ntu/NTU60_CS.npz', split='test', p_interval =[0.5, 1], window_size=32),\n",
    "            batch_size=16,\n",
    "            num_workers=0,\n",
    "            worker_init_fn=init_seed)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eea04d-f170-4b09-8fc2-dee66e57a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPSConv(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: int,\n",
    "        conv: Optional[MessagePassing],\n",
    "        heads: int = 1,\n",
    "        dropout: float = 0.0,\n",
    "        attn_dropout: float = 0.0,\n",
    "        act: str = 'relu',\n",
    "        att_type: str = 'transformer',\n",
    "        order_by_degree: bool = False,\n",
    "        shuffle_ind: int = 0,\n",
    "        d_state: int = 16,\n",
    "        d_conv: int = 4,\n",
    "        act_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        norm: Optional[str] = 'batch_norm',\n",
    "        norm_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "        self.conv = conv\n",
    "        self.heads = heads\n",
    "        self.dropout = dropout\n",
    "        self.att_type = att_type\n",
    "        self.shuffle_ind = shuffle_ind\n",
    "        self.order_by_degree = order_by_degree\n",
    "        \n",
    "        assert (self.order_by_degree==True and self.shuffle_ind==0) or (self.order_by_degree==False), f'order_by_degree={self.order_by_degree} and shuffle_ind={self.shuffle_ind}'\n",
    "        \n",
    "        if self.att_type == 'transformer':\n",
    "            self.attn = torch.nn.MultiheadAttention(\n",
    "                channels,\n",
    "                heads,\n",
    "                dropout=attn_dropout,\n",
    "                batch_first=True,\n",
    "            )\n",
    "        if self.att_type == 'mamba':\n",
    "            self.self_attn = Mamba(\n",
    "                d_model=channels,\n",
    "                d_state=d_state,\n",
    "                d_conv=d_conv,\n",
    "                expand=1\n",
    "            )\n",
    "            \n",
    "        self.mlp = Sequential(\n",
    "            Linear(channels, channels * 2),\n",
    "            activation_resolver(act, **(act_kwargs or {})),\n",
    "            Dropout(dropout),\n",
    "            Linear(channels * 2, channels),\n",
    "            Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        norm_kwargs = norm_kwargs or {}\n",
    "        self.norm1 = normalization_resolver(norm, channels, **norm_kwargs)\n",
    "        self.norm2 = normalization_resolver(norm, channels, **norm_kwargs)\n",
    "        self.norm3 = normalization_resolver(norm, channels, **norm_kwargs)\n",
    "\n",
    "        self.norm_with_batch = False\n",
    "        if self.norm1 is not None:\n",
    "            signature = inspect.signature(self.norm1.forward)\n",
    "            self.norm_with_batch = 'batch' in signature.parameters\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        if self.conv is not None:\n",
    "            self.conv.reset_parameters()\n",
    "        self.attn._reset_parameters()\n",
    "        reset(self.mlp)\n",
    "        if self.norm1 is not None:\n",
    "            self.norm1.reset_parameters()\n",
    "        if self.norm2 is not None:\n",
    "            self.norm2.reset_parameters()\n",
    "        if self.norm3 is not None:\n",
    "            self.norm3.reset_parameters()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        edge_index: Adj,\n",
    "        batch: Optional[torch.Tensor] = None,\n",
    "        **kwargs,\n",
    "    ) -> Tensor:\n",
    "        r\"\"\"Runs the forward pass of the module.\"\"\"\n",
    "        hs = []\n",
    "        if self.conv is not None:  # Local MPNN.\n",
    "            h = self.conv(x, edge_index, **kwargs)\n",
    "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "            h = h + x\n",
    "            if self.norm1 is not None:\n",
    "                if self.norm_with_batch:\n",
    "                    h = self.norm1(h, batch=batch)\n",
    "                else:\n",
    "                    h = self.norm1(h)\n",
    "            hs.append(h)\n",
    "\n",
    "        ### Global attention transformer-style model.\n",
    "        if self.att_type == 'transformer':\n",
    "            h, mask = to_dense_batch(x, batch)\n",
    "            h, _ = self.attn(h, h, h, key_padding_mask=~mask, need_weights=False)\n",
    "            h = h[mask]\n",
    "            \n",
    "        if self.att_type == 'mamba':\n",
    "            \n",
    "            if self.order_by_degree:\n",
    "                deg = degree(edge_index[0], x.shape[0]).to(torch.long)\n",
    "                order_tensor = torch.stack([batch, deg], 1).T\n",
    "                _, x = sort_edge_index(order_tensor, edge_attr=x)\n",
    "                \n",
    "            if self.shuffle_ind == 0:\n",
    "                h, mask = to_dense_batch(x, batch)\n",
    "                h = self.self_attn(h)[mask]\n",
    "            else:\n",
    "                mamba_arr = []\n",
    "                for _ in range(self.shuffle_ind):\n",
    "                    h_ind_perm = permute_within_batch(x, batch)\n",
    "                    h_i, mask = to_dense_batch(x[h_ind_perm], batch)\n",
    "                    h_i = self.self_attn(h_i)[mask][h_ind_perm]\n",
    "                    mamba_arr.append(h_i)\n",
    "                h = sum(mamba_arr) / self.shuffle_ind\n",
    "        ###\n",
    "        \n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        h = h + x  # Residual connection.\n",
    "        if self.norm2 is not None:\n",
    "            if self.norm_with_batch:\n",
    "                h = self.norm2(h, batch=batch)\n",
    "            else:\n",
    "                h = self.norm2(h)\n",
    "        hs.append(h)\n",
    "\n",
    "        out = sum(hs)  # Combine local and global outputs.\n",
    "\n",
    "        out = out + self.mlp(out)\n",
    "        if self.norm3 is not None:\n",
    "            if self.norm_with_batch:\n",
    "                out = self.norm3(out, batch=batch)\n",
    "            else:\n",
    "                out = self.norm3(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.channels}, '\n",
    "                f'conv={self.conv}, heads={self.heads})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09edbe-6945-42d9-a42f-7c4ca199713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1):\n",
    "        super(TemporalConv, self).__init__()\n",
    "        # adjust padding for kernel size so that it will be equal to out_channe;s\n",
    "        pad = (kernel_size + (kernel_size - 1) * (dilation - 1) - 1) // 2\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            # kernel_size, 1 so that we look only for spatial\n",
    "            # 3 time steps windows of only 1 node\n",
    "            kernel_size=(kernel_size, 1),\n",
    "            padding=(pad, 0),\n",
    "            stride=(stride, 1),\n",
    "            dilation=(dilation, 1),\n",
    "        )\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "class MultiScale_TemporalConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 dilations=[1, 2, 3, 4],\n",
    "                 residual=False,\n",
    "                 residual_kernel_size=1):\n",
    "\n",
    "        super().__init__()\n",
    "        assert out_channels % (len(dilations) + 2) == 0, '# out channels should be multiples of # branches'\n",
    "\n",
    "        # Multiple branches of temporal convolution\n",
    "        # + 2 because we have additional 2 branches for max and 1x1 branch\n",
    "        self.num_branches = len(dilations) + 2\n",
    "        branch_channels = out_channels // self.num_branches\n",
    "        if type(kernel_size) == list:\n",
    "            assert len(kernel_size) == len(dilations)\n",
    "        else:\n",
    "            kernel_size = [kernel_size] * len(dilations)\n",
    "        # Temporal Convolution branches\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    branch_channels,\n",
    "                    kernel_size=1,\n",
    "                    padding=0\n",
    "                ),\n",
    "                nn.BatchNorm2d(branch_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                TemporalConv(\n",
    "                    branch_channels,\n",
    "                    branch_channels,\n",
    "                    kernel_size=ks,\n",
    "                    stride=stride,\n",
    "                    dilation=dilation\n",
    "                ),\n",
    "            )\n",
    "            # checking for each dilation so that we will look for global context\n",
    "            for ks, dilation in zip(kernel_size, dilations)\n",
    "        ])\n",
    "\n",
    "        # Additional Max & 1x1 branch\n",
    "        self.branches.append(nn.Sequential(\n",
    "            nn.Conv2d(in_channels, branch_channels, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(3, 1), stride=(stride, 1), padding=(1, 0)),\n",
    "            nn.BatchNorm2d(branch_channels)  # 为什么还要加bn\n",
    "        ))\n",
    "\n",
    "        self.branches.append(nn.Sequential(\n",
    "            nn.Conv2d(in_channels, branch_channels, kernel_size=1, padding=0, stride=(stride, 1)),\n",
    "            nn.BatchNorm2d(branch_channels)\n",
    "        ))\n",
    "\n",
    "        # Residual connection\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "        else:\n",
    "            self.residual = TemporalConv(in_channels, out_channels, kernel_size=residual_kernel_size, stride=stride)\n",
    "        # print(len(self.branches))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,3,1,2)\n",
    "        # Input dim: (N,C,T,V)\n",
    "        res = self.residual(x)\n",
    "        branch_outs = []\n",
    "        for tempconv in self.branches:\n",
    "            out = tempconv(x)\n",
    "            branch_outs.append(out)\n",
    "\n",
    "        out = torch.cat(branch_outs, dim=1)\n",
    "        out += res\n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2790b42b-faad-477d-a39a-a1dc7122c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEnt(nn.Module):\n",
    "    def __init__(self, dim_in, dim, num_points=25):\n",
    "        super().__init__()\n",
    "        nn1 = Sequential(\n",
    "                nn.Linear(dim_in, dim_in),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_in, dim_in),\n",
    "            )\n",
    "        self.conv = GPSConv(dim_in, GINEConv(nn1), heads=4, attn_dropout=0.5,\n",
    "                               att_type='mamba',\n",
    "                               shuffle_ind=0,\n",
    "                               order_by_degree=True,\n",
    "                               d_state=16, d_conv=4)\n",
    "        self.lin = nn.Linear(dim_in, dim)\n",
    "        self.edge_emb = nn.Embedding(num_points*2, dim_in)\n",
    "        self_link = [(i, i) for i in range(25)]\n",
    "        inward_ori_index = [(1, 2), (2, 21), (3, 21), (4, 3), (5, 21), (6, 5), (7, 6),\n",
    "                    (8, 7), (9, 21), (10, 9), (11, 10), (12, 11), (13, 1),\n",
    "                    (14, 13), (15, 14), (16, 15), (17, 1), (18, 17), (19, 18),\n",
    "                    (20, 19), (22, 8), (23, 8), (24, 12), (25, 12)]\n",
    "        inward = [(i - 1, j - 1) for (i, j) in inward_ori_index]\n",
    "        outward = [(j, i) for (i, j) in inward]\n",
    "        self.neighbor = inward + outward\n",
    "        global device\n",
    "        self.edge_index = self.convert_neighbor_to_edge_index(self.neighbor, device)\n",
    "        self.adj_matr = torch.from_numpy(self.get_spatial_graph(25, self_link, inward, outward))\n",
    "\n",
    "    def forward(self, x, dims):\n",
    "        # N*M, T, V, C\n",
    "        N, C, T, V, M = dims\n",
    "        edge_attr = torch.ones(self.edge_index.size(1), dtype=torch.int, device=x.device)\n",
    "        edge_attr = self.edge_emb(edge_attr)\n",
    "        batch = self.create_batch_array(N, M, T, V, x.device)\n",
    "        '''N * M - number of video sequences with person number\n",
    "        C - number of channels (3d position of points)\n",
    "        T - number of frames\n",
    "        V - number of skeleton points (25)\n",
    "        order is: N*M, T, V, C\n",
    "        '''\n",
    "        _, T, V, C = x.size()\n",
    "        #x = x.view(-1, C)\n",
    "        # implement gcn here\n",
    "        #x = self.conv(x, self.adj_matr, batch, edge_attr=edge_attr)\n",
    "        #x = x.view(N*M, T, V, C)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "    def normalize_digraph(self, A):\n",
    "        Dl = np.sum(A, 0)\n",
    "        h, w = A.shape\n",
    "        Dn = np.zeros((w, w))\n",
    "        for i in range(w):\n",
    "            if Dl[i] > 0:\n",
    "                Dn[i, i] = Dl[i] ** (-1)\n",
    "        AD = np.dot(A, Dn)\n",
    "        return AD\n",
    "\n",
    "    def edge2mat(self, link, num_node):\n",
    "        A = np.zeros((num_node, num_node))\n",
    "        for i, j in link:\n",
    "            A[j, i] = 1\n",
    "        return A\n",
    "\n",
    "    def get_spatial_graph(self, num_node, self_link, inward, outward):\n",
    "        I = self.edge2mat(self_link, num_node)\n",
    "        In = self.normalize_digraph(self.edge2mat(inward, num_node))\n",
    "        Out = self.normalize_digraph(self.edge2mat(outward, num_node))\n",
    "        A = np.stack((I, In, Out))\n",
    "        return A\n",
    "\n",
    "    def convert_neighbor_to_edge_index(self, neighbor, device):\n",
    "        indices = torch.tensor(neighbor, dtype=torch.int64, device=device).t()\n",
    "        return indices\n",
    "\n",
    "    def create_batch_array(self, N, M, T, V, device):\n",
    "        # Total number of unique indices\n",
    "        num_indices = N * M \n",
    "        # Create a tensor of shape (num_indices, V) where each row contains the same index\n",
    "        batch = torch.arange(num_indices, dtype=torch.int64, device=device).repeat_interleave(V*T)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e9fba-b372-4a16-91b2-372abf348391",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphModel(nn.Module):\n",
    "    def __init__(self, dim_in, dim):\n",
    "        super().__init__()\n",
    "        self.graph_conv_first = GraphEnt(dim_in, dim)\n",
    "        self.graph_conv = GraphEnt(dim, dim)\n",
    "        self.tcn = MultiScale_TemporalConv(dim, dim, kernel_size=5, stride=1,\n",
    "                                            dilations=[1,2],\n",
    "                                            # residual=True has worse performance in the end\n",
    "                                            residual=False)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.lin = nn.Linear(dim_in, dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, 60),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, C, T, V, M = x.size()\n",
    "        dims = x.size()\n",
    "        x = x.permute(0, 4, 2, 3, 1).contiguous().view(N * M, T, V, C)\n",
    "        # N*M, T, V, C\n",
    "        layers = 5\n",
    "        #print(\"BEFORE\", x[0][0][0])\n",
    "        for i in range(layers): \n",
    "            if i == 0:\n",
    "                x = self.graph_conv_first(x, dims)\n",
    "            else:\n",
    "                #residual = x\n",
    "                x = self.graph_conv(x, dims)\n",
    "        \n",
    "        '''\n",
    "        order is: N*M, T, V, C\n",
    "        '''\n",
    "        x = x.permute(0,3,1,2)\n",
    "        _, C, T, V = x.size()\n",
    "        x = x.view(N, M, C, -1)\n",
    "        # order is: N, M, C, T*V\n",
    "        x = x.mean(3).mean(1)\n",
    "        x = self.mlp(x)\n",
    "        #print(\"RESULT\", x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5af8e0-4184-45c4-b731-62f2b96289ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    loss_value = []\n",
    "    acc_value = []\n",
    "    train_loader = load_data('train')\n",
    "    process = tqdm(train_loader, ncols=80)\n",
    "    for batch_idx, (data, label, index) in enumerate(process):\n",
    "        with torch.no_grad():\n",
    "            data = data.float().to(device)\n",
    "            label = label.long().to(device)\n",
    "        with torch.amp.autocast('cuda', enabled=use_amp):\n",
    "            out = model(data)\n",
    "            loss = lossC(out, target=label)\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        loss_value.append(loss.data.item())\n",
    "        value, predict_label = torch.max(out.data, 1)\n",
    "        acc = torch.mean((predict_label == label.data).float())\n",
    "        acc_value.append(acc.data.item())\n",
    "    return np.nanmean(loss_value), np.nanmean(acc_value)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66187d-dc25-421a-b1a7-d4d553fe003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loader = load_data('test')\n",
    "    loss_value = []\n",
    "    score_frag = []\n",
    "    process = tqdm(test_loader, ncols=80)\n",
    "    for batch_idx, (data, label, index) in enumerate(process):\n",
    "        with torch.no_grad():\n",
    "            data = data.float().to(device)\n",
    "            label = label.long().to(device)\n",
    "            out = model(data)\n",
    "            loss = lossC(out, target=label)\n",
    "            #print(out.data.cpu().numpy())\n",
    "            score_frag.append(out.data.cpu().numpy())\n",
    "            loss_value.append(loss.data.item())\n",
    "    loss = np.mean(loss_value)\n",
    "    score = np.concatenate(score_frag)\n",
    "    accuracy = test_loader.dataset.top_k(score, 1)\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea3d47e-d029-44d0-abdf-296261f90423",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seed(2)\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphModel(3, 24).to(device)\n",
    "'''devices = [3,2]\n",
    "device = devices[0]\n",
    "model = nn.DataParallel(GraphModel(3, 1024).to(device),\n",
    "                        device_ids=devices,\n",
    "                        output_device=device)'''\n",
    "optimizer = optim.SGD(\n",
    "                model.parameters(),\n",
    "                lr=0.001)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Parameters:\", count_parameters(model))\n",
    "lossC = nn.CrossEntropyLoss().to(device)\n",
    "use_amp = True\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=use_amp)\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    loss = train()\n",
    "    print(\"Loss:\", loss[0], \"Train Acc:\", loss[1])\n",
    "    print(\"AFTER:\")\n",
    "    tst = test()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss[0]:.4f}, Train Acc: {loss[1]:.4f}, Accuracy: {tst[0]}, Test_Loss: {tst[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27036341-95a8-4a22-9665-9e6ef2a3f871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
